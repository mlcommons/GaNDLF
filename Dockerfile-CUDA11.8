FROM nvidia/cuda:11.8.0-devel-ubuntu22.04
LABEL github="https://github.com/mlcommons/GaNDLF"
LABEL docs="https://mlcommons.github.io/GaNDLF/"
LABEL version=1.0
# ARG SETUPTOOLS_USE_DISTUTILS=local

# Install instructions for NVIDIA Container Toolkit allowing you to use the host's GPU: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html
# Note that to do this on a Windows host you need experimental feature "CUDA on WSL" -- not yet stable.
ENV DEBIAN_FRONTEND=noninteractive 

# Explicitly install python3.11 (this uses 11.1 for now, as PyTorch LTS 1.8.2 is built against it)
RUN apt-get update && apt-get install -y software-properties-common
RUN apt-get install -y git
RUN add-apt-repository ppa:deadsnakes/ppa
RUN apt install -y python3.11 
RUN apt install -y libpython3.11-dev 
RUN apt install -y libpython3.11 
# RUN apt install -y python-distutils-extra
RUN apt install -y python3.11-venv 
# RUN apt install -y python-setuptools
RUN apt install -y python3-pip 
RUN apt-get install -y libjpeg8-dev zlib1g-dev libffi-dev libgl1
# fix pip version because of weird PyYAML issue
RUN python3.11 -m pip install --upgrade pip
RUN python3.11 -m pip install uv
RUN uv pip install torch==2.7.1 torchvision==0.22.1 torchaudio==2.7.1 --index-url https://download.pytorch.org/whl/cu118 --system
RUN uv pip install openvino-dev opencv-python-headless --system

# Do some dependency installation separately here to make layer caching more efficient
COPY ./setup.py ./setup.py
RUN python3.11 -c "from setup import requirements; file = open('requirements.txt', 'w'); file.writelines([req + '\n' for req in requirements]); file.close()" \
  && uv pip install -r ./requirements.txt --system

COPY . /GaNDLF
WORKDIR /GaNDLF
RUN uv pip install -e . --system

# Entrypoint forces all commands given via "docker run" to go through python, CMD forces the default entrypoint script argument to be gandlf run
# If a user calls "docker run gandlf:[tag] anonymize", it will resolve to running "gandlf anonymize" instead.
# CMD is inherently overridden by args to "docker run", entrypoint is constant.
ENTRYPOINT gandlf
CMD run

# The below force the container commands to run as a nonroot user with UID > 10000.
# This greatly reduces UID collision probability between container and host, helping prevent privilege escalation attacks.
# As a side benefit this also decreases the likelihood that users on a cluster won't be able to access their files.
# See https://github.com/hexops/dockerfile as a best practices guide.
#RUN addgroup --gid 10001 --system nonroot \
# && adduser --uid 10000 --system --ingroup nonroot --home /home/nonroot nonroot

#USER nonroot

# Prepare the container for possible model embedding later.
RUN mkdir /embedded_model
