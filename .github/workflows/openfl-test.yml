# This workflow will install Python dependencies, run tests and lint with a single version of Python
# For more information see: https://help.github.com/actions/language-and-framework-guides/using-python-with-github-actions

name: OpenFL-Test

on:
  push:
    branches: [master]
  pull_request: {}

jobs:
  openfl-test:
    runs-on: ubuntu-latest

    steps:
      - name: Free space
        run: |
          df -h
          sudo rm -rf /opt/ghc
          sudo rm -rf "/usr/local/share/boost"
          sudo rm -rf "$AGENT_TOOLSDIRECTORY"
          sudo rm -rf "$ANDROID_SDK_ROOT"
          df -h
      - name: Checkout
        uses: actions/checkout@v3

      # Use changed-files-specific action to collect file changes.
      # The following commented condition applied to a step will run that step only if non-docs files have changed.
      # It should be applied to all functionality-related steps.
      # if: steps.changed-files-specific.outputs.only_modified == 'false'
      - name: Detect and screen file changes
        id: changed-files-specific
        uses: tj-actions/changed-files@v41
        with:
          files: |
            .github/*.md
            .github/ISSUE_TEMPLATE/*.md
            .github/workflows/devcontainer.yml
            .github/workflows/docker-image.yml
            .devcontainer/**
            docs/**
            mlcube/**
            *.md
            LICENSE
            Dockerfile-*

      - name: Summarize docs and non-docs modifications
        run: |
          echo "List of docs files that have changed: ${{ steps.changed-files-specific.outputs.all_modified_files }}"
          echo "Changed non-docs files: ${{ steps.changed-files-specific.outputs.other_modified_files }}"

      # This second step is unnecessary but highly recommended because
      # It will cache database and saves time re-downloading it if database isn't stale.
      - name: Cache pip
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/setup.py') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      - name: Set up Python 3.9
        if: steps.changed-files-specific.outputs.only_modified == 'false' # Run on any non-docs change
        uses: actions/setup-python@v4
        with:
          python-version: 3.9
      - name: Install dependencies and package
        if: steps.changed-files-specific.outputs.only_modified == 'false' # Run on any non-docs change
        run: |
          sudo apt-get update
          sudo apt-get install libvips libvips-tools -y
          python -m pip install --upgrade pip==24.0
          python -m pip install wheel
          pip install torch==2.2.1 torchvision==0.17.1 torchaudio==2.2.1 --index-url https://download.pytorch.org/whl/cpu
          pip install -e .
      - name: Run generic unit tests to download data and construct CSVs
        if: steps.changed-files-specific.outputs.only_modified == 'false' # Run on any non-docs change
        run: |
          pytest --cov=. --cov-report=xml -k "prepare_data_for_ci"
      # openfl tests start here
      - name: Run OpenFL tests
        if: steps.changed-files-specific.outputs.only_modified == 'false' # Run on any non-docs change
        run: |
          echo "Removing onnx because of protobuf version conflict"
          pip uninstall onnx -y
          echo "Installing OpenFL"
          git clone --depth=1 https://github.com/securefederatedai/openfl.git
          cd openfl
          git fetch --tags
          # echo "Checkout the latest OpenFL tag"
          # latestTag=$(git describe --tags "$(git rev-list --tags --max-count=1)")
          # git checkout $latestTag
          # sed -i -e 's/protobuf==3.19.6/protobuf/g' setup.py ## this should NOT be there
          pip install -e .
          cd ..
          echo "Copying files to appropriate directories and updated headers"
          head -n 1 testing/data/train_2d_rad_segmentation.csv > /home/runner/work/GaNDLF/GaNDLF/openfl/valid.csv
          tail -n +9 testing/data/train_2d_rad_segmentation.csv >> /home/runner/work/GaNDLF/GaNDLF/openfl/valid.csv
          head -n 8 testing/data/train_2d_rad_segmentation.csv > /home/runner/work/GaNDLF/GaNDLF/openfl/train.csv
          sed -i 's/# n_channels: 3/num_channels: 3/g' testing/config_segmentation.yaml
          config_to_use=$(pwd)/testing/config_segmentation.yaml
          cd openfl
          python -m tests.github.test_gandlf --template gandlf_seg_test --fed_workspace aggregator --col1 one --col2 two --rounds-to-train 1 --gandlf_config $config_to_use
